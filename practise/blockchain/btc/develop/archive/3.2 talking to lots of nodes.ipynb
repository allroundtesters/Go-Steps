{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap\n",
    "\n",
    "In the first lesson we learned to interpret the outermost layer of the Bitcoin Protocol onion: the [message structure](https://en.bitcoin.it/wiki/Protocol_documentation#Message_structure). We learned to send a `version` message to Bitcoin Network peers and listen for their `version` response. We learned to read this response and check that the correct `magic` bytes came at the beginning of the message; to interpret which of the 27 `command` types the message is; to read `payload` data associated with the command and the check the payload with a `checksum` given to us by our remote peer;\n",
    "\n",
    "In the second lesson we learned to peel another layer or two of the onion. We learned to read the [payload](https://en.bitcoin.it/wiki/Protocol_documentation#version) of `version` messages. Along the way we had to figure out how to interpret all the sub-structures of the data, such as variable-length strings\", variable-length integers, network addresses, `services` bitfields, Unix timestamps, and big-endian encoded port numbers.\n",
    "\n",
    "We've come a long way, but we still have a long way to go.\n",
    "\n",
    "# Getting To Know Each Other\n",
    "\n",
    "Now that we can talk to our peers, let's be friendly neighbors and introduce ourself.\n",
    "\n",
    "In this lesson we will connect to the nearl 10,000 Bitcoin Network peers that operate out in the open. We'll send each a `version` message and we'll record for their responses. Our first attempts at this will be far too slow and we will learn about \"concurrent programming\" -- a technique that frees our program to work on many things at once, in our case talking to Bitcoin Network peers.\n",
    "\n",
    "Lastly we'll do some \"data science\" to find patterns in this sea of bytes. FIXME more words/\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bitnodes.earn.com\n",
    "\n",
    "The first thing we did in the first lesson was to pull up [this website](https://bitnodes.earn.com/nodes/) and look for the IP address of some other node to talk to. \n",
    "\n",
    "Now we're going to write some Python code to do this for us.\n",
    "\n",
    "bitnodes.earn.com offers [a free, unauthenticated API](https://bitnodes.earn.com/api/#list-nodes) to help us do this. You've probably heard this word before -- API -- and you probably don't know exactly what it means. The acronym [API](https://en.wikipedia.org/wiki/Application_programming_interface) stands for \"Application Programming Interface\". An \"Application Programming Interface\" is a description of how a programmer can interact with a piece of software. For example, Python has an API for converting `bytes` to `int`s: [int.from_bytes(bytes, byteorder, \\*, signed=False)](https://docs.python.org/3/library/stdtypes.html#int.from_bytes). Python defines this exact function allowing programmers to accomplish this exact operation. There are multiple different \"implementations\" of python -- CPython, PyPy, MicroPython etc -- and they all implement this same API.\n",
    "\n",
    "So that's the original meaning of the term \"application programming interface\". But it's most frequently used describe this sort of thing in a specific domain: web programming. Please read this [explainer](https://medium.freecodecamp.org/what-is-an-api-in-english-please-b880a3214a82) of this more narrow definition of the term. The [earn.com API](https://bitnodes.earn.com/api/) is one such example of \"API\" in this sense of the word.\n",
    "\n",
    "The earn.com API is free and also \"unauthenticated\" which means we don't have to present any kind of credential in order to use this -- stock market data APIs, for one, aren't so kind!\n",
    "\n",
    "The API has this specific [List Nodes endpoint](https://bitnodes.earn.com/api/#list-nodes) which will give a list of every node they are aware of at present or some specific point in the past. We are able to specify \n",
    "\n",
    "To \"exercise\" this API we need to send a GET http request. This is the same sort of request that your browser sense every time you load a webpage. It just fetches data.\n",
    "\n",
    "### cURL: A Terminal Utility\n",
    "\n",
    "Go to your command line and type this in:\n",
    "\n",
    "```\n",
    "$ curl -H \"Accept: application/json; indent=4\" https://bitnodes.earn.com/api/v1/snapshots/latest/\n",
    "```\n",
    "\n",
    "(If you get any error you probably need to install the cURL program. Google it!)\n",
    "\n",
    "This should spit a huge amoutn of \"JSON\" out onto your terminal. This is a complete list of all Bitcoin Network nodes which earn.com has been able to find.\n",
    "\n",
    "### Requests: A Python Library\n",
    "\n",
    "This is great, but we need to find a way to do this from Python. This is where the `requests` library comes in. Watch [this video](https://www.youtube.com/watch?v=_8HPCToXdAk) to learn how to use `requests`\n",
    "\n",
    "##### Exercise #1: Use `requests.get` to make the same https request we made using cURL above.\n",
    "\n",
    "Return a dictionary of the JSON response from the API \n",
    "\n",
    "another hint: [Relevant part](https://youtu.be/_8HPCToXdAk?t=3m12s) of Youtube video above.\n",
    "\n",
    "hint: `.json()` get's the JSON response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_bitnodes_api_response():\n",
    "    BITNODES_URL = \"https://bitnodes.earn.com/api/v1/snapshots/latest/\"\n",
    "    ### YOUR CODE ###\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bitnodes_api_response():\n",
    "    BITNODES_URL = \"https://bitnodes.earn.com/api/v1/snapshots/latest/\"\n",
    "    return requests.get(BITNODES_URL).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "nodes_json = open(\"ibd/four/response.json\").read()\n",
    "nodes_dict = json.loads(nodes_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipytest, requests_mock\n",
    "\n",
    "def test_get_bitnodes_api_response():\n",
    "    BITNODES_URL = \"https://bitnodes.earn.com/api/v1/snapshots/latest/\"\n",
    "    with requests_mock.mock() as mock:\n",
    "        mock.get(BITNODES_URL, json=nodes_dict)\n",
    "        response = get_bitnodes_api_response()\n",
    "        assert response == nodes_dict\n",
    "\n",
    "ipytest.run_tests(doctest=True)\n",
    "ipytest.clean_tests(\"test_get_bitnodes_api_response*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise #2: Call the bitnodes API and return just the `\"nodes\"` part of the JSON response\n",
    "\n",
    "hint: relevant part of the YouTube video, where you grab the value corresponding to the `name` key from the `r.json()` response JSON dictionary. We're doing the same thing in this exercise, just looking up the `nodes` key instead of the `name` key.\n",
    "```\n",
    "r = requests.get(\"http://swapi.co/api/people/1\")\n",
    "r.json()['name']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes():\n",
    "    BITNODES_URL = \"https://bitnodes.earn.com/api/v1/snapshots/latest/\"\n",
    "    ### YOUR CODE ###\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes():\n",
    "    data = get_bitnodes_api_response()\n",
    "    return data['nodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_nodes():\n",
    "    BITNODES_URL = \"https://bitnodes.earn.com/api/v1/snapshots/latest/\"\n",
    "    with requests_mock.mock() as mock:\n",
    "        mock.get(url, json=example_data)\n",
    "        nodes = get_nodes()\n",
    "        assert nodes == nodes_dict['nodes']\n",
    "\n",
    "ipytest.run_tests(doctest=True)\n",
    "ipytest.clean_tests(\"test_get_nodes*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise #FIXME: Turn the `nodes` object into a list of `ip:port` string addresses\n",
    "\n",
    "_Notice that the keys of the `node` object are `ip:port`_\n",
    "\n",
    "This exercise just asks you to turn a dictionary into a list of it's keys. There's a built-in `dict` method to do this. Look it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodes_to_address_strings(nodes):\n",
    "    raise NotImplementedError()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodes_to_address_strings(nodes):\n",
    "    return nodes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_nodes = {\n",
    "    \"192.168.0.1:8333\": {}, # ipv4\n",
    "    \"FE80:CD00:0:CDE:1257:0:211E:729C:8333\": {}, # ipv6\n",
    "}\n",
    "\n",
    "def test_nodes_to_address_strings():\n",
    "    address_strings = nodes_to_address_strings(mock_nodes)\n",
    "    solution_set = {\"192.168.0.1:8333\", \"FE80:CD00:0:CDE:1257:0:211E:729C:8333\"}\n",
    "    assert set(address_strings) == solution_set\n",
    "\n",
    "ipytest.run_tests(doctest=True)\n",
    "ipytest.clean_tests(\"test_nodes_to_address_strings*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise #FIXME: Turn the `nodes` object into a list of `(ip, port)` tuples where ip is a string and port is an integer\n",
    "\n",
    "If you recall, [`socket.connect`](https://docs.python.org/3/library/socket.html#socket.socket.connect) takes such a tuple as its argument. This is why I want you to do this. Once we have a list of every such tuple we can iterate across it and connect to every node.\n",
    "\n",
    "note: this is a challenging exercise\n",
    "\n",
    "FIXME: explain this as the gameplan / objective at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodes_to_address_tuples(nodes):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodes_to_address_tuples(nodes):\n",
    "    address_strings = nodes.keys()\n",
    "    address_tuples = []\n",
    "    for address_string in address_strings:\n",
    "        ip, port = address_string.rsplit(\":\", 1)\n",
    "        address_tuple = (ip, int(port))\n",
    "        address_tuples.append(address_tuple)\n",
    "    return address_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_nodes = {\n",
    "    \"192.168.0.1:8333\": {}, # ipv4\n",
    "    \"FE80:CD00:0:CDE:1257:0:211E:729C:8333\": {}, # ipv6\n",
    "}\n",
    "solution_set = {\n",
    "    (\"192.168.0.1\", 8333), \n",
    "    (\"FE80:CD00:0:CDE:1257:0:211E:729C\", 8333),\n",
    "}\n",
    "\n",
    "def test_nodes_to_address_tuples():\n",
    "    address_tuples = nodes_to_address_tuples(mock_nodes)\n",
    "    assert set(address_tuples) == solution_set\n",
    "\n",
    "ipytest.run_tests(doctest=True)\n",
    "ipytest.clean_tests(\"test_nodes_to_address_tuples*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling All Nodes!\n",
    "\n",
    "Now we have a list of address tuples -- just like the `socket.connect` API uses. Let's iterate over them and download version messages from every node.\n",
    "\n",
    "This `get_version_message` just takes the takes what we did in lesson 2 and turns it into a function. \n",
    "\n",
    "`get_version_messages` iterates across every `address_tuple` in `address_tuples` (obtainable with `nodes_to_address_tuples(get_nodes())`, calls `get_version_message(address_tuple)`, stores the results and logs some information about the progress its making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "from ibd.two.complete import Packet, VersionMessage # get the final version ...\n",
    "\n",
    "OUR_VERSION = b'\\xf9\\xbe\\xb4\\xd9version\\x00\\x00\\x00\\x00\\x00j\\x00\\x00\\x00\\x9b\"\\x8b\\x9e\\x7f\\x11\\x01\\x00\\x0f\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x93AU[\\x00\\x00\\x00\\x00\\x0f\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0f\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00rV\\xc5C\\x9b:\\xea\\x89\\x14/some-cool-software/\\x01\\x00\\x00\\x00\\x01'\n",
    "\n",
    "def get_version_message(address_tuple):\n",
    "    sock = socket.socket()\n",
    "    sock.settimeout(1) # only wait 1 second for connections / responses\n",
    "    sock.connect(address_tuple)\n",
    "    sock.send(OUR_VERSION)\n",
    "    packet = Packet.from_socket(sock)\n",
    "    version_message = VersionMessage.from_bytes(packet.payload)\n",
    "    sock.close()\n",
    "    return version_message\n",
    "    \n",
    "def get_version_messages(address_tuples):\n",
    "    version_messages = []\n",
    "    exceptions = []\n",
    "    for address_tuple in address_tuples:\n",
    "        try:\n",
    "            version_message = get_version_message(address_tuple)\n",
    "        except Exception as e:\n",
    "            exceptions.append(e)\n",
    "            continue\n",
    "        version_messages.append(version_message)\n",
    "        \n",
    "        successes = len(version_messages)\n",
    "        total = len(address_tuples)\n",
    "        failures = len(exceptions)\n",
    "        remaining = total - (successes + failures)\n",
    "        progress = (successes + failures) / total\n",
    "        print(f\"{successes} Received | {failures} Failures | {remaining} Remaining | {progress:.3f}% Complete\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = get_nodes()\n",
    "address_tuples = nodes_to_address_tuples(nodes)\n",
    "get_version_messages(address_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After about 10 seconds of waiting for this cell to finish executing, I hope you start to wonder if our code might be running too slow? What's going on? Are we progressing? Are we stuck?\n",
    "\n",
    "It's time to add a little logging to better understand what's happening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_version_messages_logger(address_tuples, version_messages, exceptions, start_time):\n",
    "    successes = len(version_messages)\n",
    "    total = len(address_tuples)\n",
    "    failures = len(exceptions)\n",
    "    now = time.time()\n",
    "    elapsed = now - start_time\n",
    "    \n",
    "    remaining = total - (successes + failures)\n",
    "    progress = (successes + failures) / total\n",
    "    seconds_remaining = elapsed / progress\n",
    "    minutes_remaining = seconds_remaining / 60\n",
    "    \n",
    "    print(f\"{successes} Received | {failures} Failures | {remaining} Remaining | {progress:.3f}% Complete | ~{minutes_remaining:.0f} Minutes Left\")\n",
    "\n",
    "def get_version_messages(address_tuples, logger=False):\n",
    "    version_messages = []\n",
    "    exceptions = []\n",
    "    start_time = time.time()\n",
    "    for address_tuple in address_tuples:\n",
    "        try:\n",
    "            version_message = get_version_message(address_tuple)\n",
    "        except Exception as e:\n",
    "            exceptions.append(e)\n",
    "            continue\n",
    "        version_messages.append(version_message)\n",
    "        if logger:\n",
    "            logger(address_tuples, version_messages, exceptions, start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = get_nodes()\n",
    "address_tuples = nodes_to_address_tuples(nodes)\n",
    "get_version_messages(address_tuples, logger=get_version_messages_logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling -- Exactly Where is our Code Slow?\n",
    "\n",
    "Do you feel like waiting around for an hour for all these version messages to download? I don't ...\n",
    "\n",
    "In order to improve our lot, we first need to understand _why_ our code is slow. Analyzing the speed of a program is one aspect of the discipline of [\"profiling\"](https://en.wikipedia.org/wiki/Profiling_(computer_programming)).\n",
    "\n",
    "To profile our slow code and understand figure out why it's so slow, we're going to use a tool called [line_profiler](https://github.com/rkern/line_profiler/). [Here is a nice tutorial](https://jakevdp.github.io/PythonDataScienceHandbook/01.07-timing-and-profiling.html) that describes a few methods of profiling python code, including line_profiler. Please read it.\n",
    "\n",
    "To use `version_profiler` we first, we load line_profiler as an Jupyter extension. Next, we run our `get_version_message` function through it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f get_version_message get_version_message(address_tuples[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see something like this at the bottom of your Jupyter window:\n",
    "\n",
    "![image](images/profiler.png)\n",
    "\n",
    "If you look in the \"% Time\" column, you will see that the `sock.connect` and `sock.recv` (called by `Packet.from_socket`) calls are each taking up about 50% of the time. It's not because these functions are \"slow\" or \"unoptimized\" -- no, it's because they're waiting for a response from our peer; they're \"blocked\". And this function is blocked, the Python interpreter can't do any other work.\n",
    "\n",
    "Concurrent programming techniques offer away around some of the problems of blocking code. They allow us to chunk our programe into bite-sized tasks which your computer switch between whenever one gets blocked, and then picking each task back up every time they are un-blocked (e.g. our peer accepts the TCP connection from `sock.connect` and it returns).\n",
    "\n",
    "But concurrent programming (multi-threading being one approach to concurrency) can be very difficult:\n",
    "\n",
    "![image](./images/this-tall.jpg)\n",
    "\n",
    "We'll need concurrency, however, when we write our initial-block-downloader, so let's dip our toes into Python concurrency.\n",
    "\n",
    "Please read [this tutorial](https://code.tutsplus.com/articles/introduction-to-parallel-and-concurrent-programming-in-python--cms-28612), and stop at the \"Gevent\" section. You'll learn to write a concurrent web-scraper using multiple \"threads\" and multiple \"processes\". And take note: the `get_version_messages` function we're trying to speed up is basically a web scraper. Try to anticipate how these techniques apply to our situation. Can you write a multi-threaded or multi-process `get_version_messages` function?\n",
    "\n",
    "### Translating The Tutorial\n",
    "\n",
    "This is kind of the key block of code from the tutorial\n",
    "\n",
    "![image](images/run-tasks.png)\n",
    "\n",
    "Let's translate it into out problem space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_logger():\n",
    "    print(f\"PID: {os.getpid()} | Process Name: {multiprocessing.current_process().name} | Thread Name: {threading.current_thread().name}\")\n",
    "\n",
    "def target(address, logger):\n",
    "    get_version_message(address)\n",
    "    logger()\n",
    "\n",
    "def concurrent_demo(addresses, logger):\n",
    "    start_time = time.time()\n",
    "    for address in addresses:\n",
    "        target(address, logger)\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(\"Serial time=\", end_time - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    threads = [\n",
    "        threading.Thread(target=target, args=(address, logger))\n",
    "        for address in addresses\n",
    "    ]\n",
    "    for thread in threads:\n",
    "        thread.start()\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(\"Threads time=\", end_time - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    processes = [\n",
    "        multiprocessing.Process(target=target, args=(address, logger))\n",
    "        for address in addresses\n",
    "    ]\n",
    "    for process in processes:\n",
    "        process.start()\n",
    "    for process in processes[::-1]:  # FIXME\n",
    "        process.join()\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(\"Parallel time=\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concurrent_demo(address_tuples[9:13], base_logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Race Conditions\n",
    "\n",
    "If you run this enough times you may notice that the printing gets messed up. This bug has occurred in the image below. The third line of the \"threading\" section contains two messages, but the fourth line is empty! This is because the different threads might print at exactly the same time, making their output interfere. This is called a \"race condition\", and it's the worst enemy of the multi-threaded program. If you'd like to learn more, check out [this phenominal talk on concurrency by Python core contributer Raymond Hettinger](https://www.youtube.com/watch?v=Bv25Dwe84g).\n",
    "\n",
    "![image](images/race-conditions.png)\n",
    "\n",
    "We'll use a technique covered in the video to demonstrate how to make the race conditions worse. If we put tiny little `time.sleep` calls in our code, things no longer happen in the order we were expecting.\n",
    "\n",
    "TODO: more explanation of why this breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME print-based fuzzing breaks threads but not processes\n",
    "# stdout.write breaks processes\n",
    "# FIXME contact raymond hettinger about this\n",
    "# perhaps .join\n",
    "\n",
    "import random\n",
    "\n",
    "from sys import stdout\n",
    "\n",
    "def fuzz():\n",
    "    time.sleep(random.random() / 10)\n",
    "\n",
    "\n",
    "# def fuzz_logger():\n",
    "#     fuzz()\n",
    "#     stdout.write(f\"PID: {os.getpid()} | \")\n",
    "#     stdout.flush()\n",
    "#     fuzz()\n",
    "#     stdout.write(f\"Process Name: {multiprocessing.current_process().name} | \")\n",
    "#     stdout.flush()\n",
    "#     fuzz()\n",
    "#     print(f\"Thread Name: {threading.current_thread().name}\", end=\"\\n\")\n",
    "    \n",
    "def fuzz_logger():\n",
    "    \n",
    "    print(f\"PID: {os.getpid()}\", end=\" | \")\n",
    "    fuzz()\n",
    "    print(f\"Process Name: {multiprocessing.current_process().name}\", end=\" | \")\n",
    "    fuzz()\n",
    "    print(f\"Thread Name: {threading.current_thread().name}\", end=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Our Synchronous code has no race conditions\")\n",
    "# print(\"===========================================\")\n",
    "# for address in address_tuples[:4]:\n",
    "#     get_version_message(address)\n",
    "#     logger()\n",
    "\n",
    "# print(\"\\n\")\n",
    "\n",
    "# print(\"Threaded code easily owned by race conditions\")\n",
    "# print(\"=============================================\")\n",
    "\n",
    "concurrent_demo(address_tuples[71:75], fuzz_logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how nicely the normal, synchronous code prints its little log statements?\n",
    "\n",
    "See *exactly the same logging code* produces unreadable output when run in different threads?\n",
    "\n",
    "How can we fix it?\n",
    "\n",
    "The answer is to only let one thread print -- the `MainThread`. We can accomplish this by having our logger send every message to the main thread via a simple \"queue\" instead of printing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "\n",
    "log_queue = queue.Queue()\n",
    "\n",
    "def log_producer():\n",
    "    message = f\"PID: {os.getpid()} | Process Name: {multiprocessing.current_process().name} | Thread Name: {threading.current_thread().name}\"\n",
    "    log_queue.put(message)\n",
    "    \n",
    "def log_consumer():\n",
    "    while True:\n",
    "        try:\n",
    "            message = log_queue.get(timeout=1)\n",
    "        except queue.Empty:\n",
    "            # Queue is empty\n",
    "            break\n",
    "        print(message)\n",
    "    \n",
    "def get_version_messages_threaded_demo(addresses):\n",
    "    start = time.time()\n",
    "    threads = []\n",
    "\n",
    "    # spawn 10 threads and start them\n",
    "    # append the threads to `threads` list so that we can wait for them to finish\n",
    "    # one problem -- can't get the results!\n",
    "    for address in addresses:\n",
    "        # FIXME exceptions not handled\n",
    "        thread = threading.Thread(target=get_version_message, \n",
    "                         args=(address,), \n",
    "                         kwargs={\"logger\": log_producer})\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "\n",
    "    for thread in threads:\n",
    "        # wait for each thread to finish executing\n",
    "        thread.join()\n",
    "        \n",
    "    end = time.time()\n",
    "    \n",
    "    log_consumer()\n",
    "    \n",
    "    print(f\"It took {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Our Synchronous code has no race conditions\")\n",
    "print(\"===========================================\")\n",
    "for address in address_tuples[:4]:\n",
    "    get_version_message(address, logger=concurrent_log)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Queues helps eliminate race conditions in concurrent code\")\n",
    "print(\"=========================================================\")\n",
    "\n",
    "get_version_messages_threaded_demo(address_tuples[20:24])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks nice, but we still have another problem: how can we retrieve the version message from the thread when it finishes executing? Python doesn't have a built-in way to extrace \"return value\" from a thread in this way.\n",
    "\n",
    "What can we do? Hint: it starts with a \"Q\"!\n",
    "\n",
    "Previously we created a `log_queue` to keep track of our logging messages until our main thread got around to printing them out for us.\n",
    "\n",
    "Now, we will create a `version_message_queue` which allows each thread to submit something like their \"return value\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "\n",
    "version_message_queue = queue.Queue()\n",
    "    \n",
    "def get_version_messages_threaded_demo(addresses):\n",
    "    start = time.time()\n",
    "    threads = []\n",
    "    \n",
    "    # FIXME: this style is different from the logging code \n",
    "    # in get_version_message choose one style or the other\n",
    "    def target(*args, **kwargs):\n",
    "        q = kwargs.pop(\"result_queue\")\n",
    "        result = get_version_message(*args, **kwargs)\n",
    "        q.put(result)\n",
    "            \n",
    "    for address in addresses:\n",
    "        thread = threading.Thread(target=target, \n",
    "                         args=(address,), \n",
    "                         kwargs={\"result_queue\": version_message_queue})\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "\n",
    "    for thread in threads:\n",
    "        # wait for each thread to finish executing\n",
    "        thread.join()\n",
    "        \n",
    "    end = time.time()\n",
    "    \n",
    "    log_consumer()\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            version_message = version_message_queue.get(timeout=1)\n",
    "        except queue.Empty:\n",
    "            # Queue is empty\n",
    "            break\n",
    "        print(version_message)\n",
    "    \n",
    "    print(f\"It took {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_version_messages_threaded_demo(address_tuples[80:81])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go. Our threaded code is now acceptible. It doesn't have any race conditions and the main thread can get `version` message \"return values\" from all the threads it spawns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing\n",
    "\n",
    "Here's how to accomplish concurrent version message downloads using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_producer(q, func=None):\n",
    "    def producer(*args, **kwargs):\n",
    "        if func:\n",
    "            r = func(*args, **kwargs)\n",
    "        else:\n",
    "            r = args[0]  # if no callback supplied just take the first argument\n",
    "        q.put(r)\n",
    "    return producer\n",
    "\n",
    "def make_target(func, producers):\n",
    "    \"\"\"Return function that calls func, then calls all functions in `producers`\"\"\"\n",
    "    def target(*args, **kwargs):\n",
    "        result = func(*args, **kwargs)\n",
    "        for producer in producers:\n",
    "            producer(result)\n",
    "    return target\n",
    "\n",
    "def logger(result):\n",
    "    return f\"PID: {os.getpid()} | Process Name: {multiprocessing.current_process().name} | Thread Name: {threading.current_thread().name}\"\n",
    "\n",
    "def consume(q, callback=print):\n",
    "    while True:\n",
    "        try:\n",
    "            version_message = q.get(timeout=1)\n",
    "        except queue.Empty:\n",
    "            # Queue is empty\n",
    "            break\n",
    "        callback(version_message)\n",
    "\n",
    "def spawn_processes(target, addresses, producers):\n",
    "    processes = []\n",
    "    for address in addresses:\n",
    "        process = multiprocessing.Process(target=target, args=(address,))\n",
    "        processes.append(process)\n",
    "        process.start()\n",
    "    for process in processes:\n",
    "        process.join()\n",
    "        \n",
    "\n",
    "def get_version_messages_multiprocess_demo(addresses, log=False, results=False):\n",
    "    producers = []\n",
    "    log_queue = multiprocessing.Queue()\n",
    "    result_queue = multiprocessing.Queue()\n",
    "    result_producer = make_producer(result_queue)\n",
    "    log_producer = make_producer(log_queue, func=logger)\n",
    "    \n",
    "    if log:\n",
    "        producers.append(log_producer)\n",
    "    if results:\n",
    "        producers.append(result_producer)\n",
    "   \n",
    "    target = make_target(get_version_message, producers)\n",
    "    spawn_processes(target, addresses, producers)\n",
    "    \n",
    "    if log:\n",
    "        consume(log_queue)\n",
    "    if results:\n",
    "        consume(result_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_version_messages_multiprocess_demo(address_tuples[9:11], log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: this is printing None's WTFFFFF\n",
    "get_version_messages_multiprocess_demo(address_tuples[73:75], results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's update the threading code ...\n",
    "\n",
    "def spawn_threads(target, addresses, producers):\n",
    "    threads = []\n",
    "    for address in addresses:\n",
    "        thread = threading.thread(target=target, args=(address,))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "        \n",
    "def get_version_messages_threading_demo(addresses, log=False, results=False):\n",
    "    producers = []\n",
    "    log_queue = queue.Queue()\n",
    "    result_queue = queue.Queue()\n",
    "    result_producer = make_producer(result_queue)\n",
    "    log_producer = make_producer(log_queue, func=logger)\n",
    "    \n",
    "    if log:\n",
    "        producers.append(log_producer)\n",
    "    if results:\n",
    "        producers.append(result_producer)\n",
    "   \n",
    "    target = make_target(get_version_message, producers)\n",
    "    spawn_threads(target, addresses, producers)\n",
    "    \n",
    "    if log:\n",
    "        consume(log_queue)\n",
    "    if results:\n",
    "        consume(result_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_version_messages_multiprocess_demo(address_tuples[9:11], log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_version_messages_multiprocess_demo(address_tuples[9:11], results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. No know how to do threaded and multi-process code. How do they stack up against good old synchronous code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME fill in with the x_demo functions we've written\n",
    "\n",
    "def concurrent_demo(addresses):\n",
    "    addresses = addresses[:8]\n",
    "\n",
    "    start_time = time.time()\n",
    "    for address in addresses:\n",
    "        get_version_message(address, logger=concurrent_log)\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(\"Serial time=\", end_time - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    threads = [\n",
    "        threading.Thread(target=get_version_message, args=(address,), kwargs={\"logger\": concurrent_log})\n",
    "        for address in addresses\n",
    "    ]\n",
    "    [thread.start() for thread in threads]\n",
    "    [thread.join() for thread in threads]\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(\"Threads time=\", end_time - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    processes = [\n",
    "        multiprocessing.Process(\n",
    "            target=get_version_message, args=(address,), kwargs={\"logger\": concurrent_log}\n",
    "        )\n",
    "        for address in addresses\n",
    "    ]\n",
    "    [process.start() for process in processes]\n",
    "    [process.join() for process in processes]\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(\"Parallel time=\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME fill in with the x_demo functions we've written\n",
    "\n",
    "def concurrent_demo(addresses):\n",
    "    addresses = addresses[:8]\n",
    "\n",
    "    start_time = time.time()\n",
    "    for address in addresses:\n",
    "        get_version_message(address, logger=concurrent_log)\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(\"Serial time=\", end_time - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    threads = [\n",
    "        threading.Thread(target=get_version_message, args=(address,), kwargs={\"logger\": concurrent_log})\n",
    "        for address in addresses\n",
    "    ]\n",
    "    [thread.start() for thread in threads]\n",
    "    [thread.join() for thread in threads]\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(\"Threads time=\", end_time - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    processes = [\n",
    "        multiprocessing.Process(\n",
    "            target=get_version_message, args=(address,), kwargs={\"logger\": concurrent_log}\n",
    "        )\n",
    "        for address in addresses\n",
    "    ]\n",
    "    [process.start() for process in processes]\n",
    "    [process.join() for process in processes]\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(\"Parallel time=\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concurrent_demo(address_tuples[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks at that!\n",
    "\n",
    "Using the same code from the tutorial we are able to speed up our function 3 times!\n",
    "\n",
    "Take note:\n",
    "* The the first block of code runs entirely within the same \"MainProcess\" and \"MainThread\"\n",
    "* The second, threaded block of code runs entirely within the \"MainProcess\" but within 4 different threads attached to that \"MainProcess\".\n",
    "* The third, multi-process block of code spawns executes across 4 different process, but within each process the code executes in the \"MainThread\"\n",
    "* Lastly, not that the multi-threaded version is a little faster than the multi-process version. This is because threads are a little \"lighter weight\" than processes so they start faster, and we aren't doing any CPU-intensive number crunching where multi-processing is able to spread the work across the multiple cores of your laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloader TODO\n",
    "* make a short list of known-good, always up nodes from the bitnodes leaderboard. use these for the little demos.\n",
    "* extract start and stop times for ^^ and print using matplotlib\n",
    "    * wouldn't it be dope if more than 1 task ran at a time?\n",
    "    * maybe also pull out some other timestamps demonstrating that all time is spent waiting for the remote peer.\n",
    "* `get_versions_threaded(addrs)`\n",
    "    * first just prints\n",
    "    * second uses queue to communicate with main thread\n",
    "* `get_versions_multiprocess(addrs)\n",
    "* Print out the cool display showing how threads / processes are fast and how they're actually doing work in different threads / processes\n",
    "* Graph how they're doing work concurrently\n",
    "* (optional) given an example of a cpu-intensive task where multipprocessing excels (fib in a nod to David Beazley?)\n",
    "* async / await version with `curio`\n",
    "    * let's avoid having to use TaskGroup initially ... just obscures what's going on\n",
    "* someday, write a crawler just like bitnodes (we're kind of trusting them right now)\n",
    "\n",
    "Conclusion\n",
    "* some of this may have seemed like a bit of a needless tangent, but I assure it was not. When we finally implement our intial-block-downloader we will need to stay connected to many peers at the same time and concurrently download blocks from each of them. Our code must not have race conditions, and it must have a central, controlling task manager that can supervise the connections to our peers and assemble valid blockchain. We will spend a lot of time profiling and optimizing our code because initial block download must be as fast as possible.\n",
    "\n",
    "Homework:\n",
    "* Make some kind of graphical representation of the data we receive from our peers\n",
    "* This is the bitnodes crawler: https://github.com/ayeowch/bitnodes. Try to write your own. This would simply involve connecting to a peer, sending them a `getaddr` message, listening for the `addr` response, then doing the verack handshake with each address contained in the `addr` message, and repeat -- taking care to log each version message you receive. Not that bitnodes skips any nodes running versions < 70001. Can you find some nodes with lower version numbers than that?\n",
    "* A related idea to the above idea -- what if you sent `getaddr` messages to every peer that bitnodes gave us, listened for and saved the convents of each peer's `addr` response. Then you see if our peers will tell us about any nodes that bitnodes doesn't includ -- this is probably the best approach to find old nodes.\n",
    "\n",
    "Data Science TODO\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
